<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../../../">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>devinterp.slt.sampler &mdash; devinterp 0.3.0 documentation</title>
      <link rel="stylesheet" type="text/css" href="../../../_static/pygments.css?v=92fd9be5" />
      <link rel="stylesheet" type="text/css" href="../../../_static/css/theme.css?v=19f00094" />

  
  <!--[if lt IE 9]>
    <script src="../../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script src="../../../_static/jquery.js?v=5d32c60e"></script>
        <script src="../../../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
        <script src="../../../_static/documentation_options.js?v=e259d695"></script>
        <script src="../../../_static/doctools.js?v=888ff710"></script>
        <script src="../../../_static/sphinx_highlight.js?v=dc90522c"></script>
        <script src="../../../_static/custom.js"></script>
    <script src="../../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../../genindex.html" />
    <link rel="search" title="Search" href="../../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../../../index.html" class="icon icon-home">
            devinterp
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <ul>
<li class="toctree-l1"><a class="reference internal" href="../../../index.html">Welcome to devinterpâ€™s documentation!</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../devinterp.slt.html">SLT Observables</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../devinterp.optim.html">Sampling Methods</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../devinterp.utils.html">Utils &amp; Visualisation Methods</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../../index.html">devinterp</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../../index.html" class="icon icon-home" aria-label="Home"></a></li>
          <li class="breadcrumb-item"><a href="../../index.html">Module code</a></li>
      <li class="breadcrumb-item active">devinterp.slt.sampler</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for devinterp.slt.sampler</h1><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">inspect</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="kn">from</span> <span class="nn">copy</span> <span class="kn">import</span> <span class="n">deepcopy</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Callable</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Literal</span><span class="p">,</span> <span class="n">Optional</span><span class="p">,</span> <span class="n">Type</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.multiprocessing</span> <span class="kn">import</span> <span class="n">cpu_count</span><span class="p">,</span> <span class="n">get_context</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span>
<span class="kn">from</span> <span class="nn">tqdm</span> <span class="kn">import</span> <span class="n">tqdm</span>

<span class="kn">from</span> <span class="nn">devinterp.optim.sgld</span> <span class="kn">import</span> <span class="n">SGLD</span>
<span class="kn">from</span> <span class="nn">devinterp.slt.callback</span> <span class="kn">import</span> <span class="n">SamplerCallback</span><span class="p">,</span> <span class="n">validate_callbacks</span>
<span class="kn">from</span> <span class="nn">devinterp.slt.llc</span> <span class="kn">import</span> <span class="n">LLCEstimator</span><span class="p">,</span> <span class="n">OnlineLLCEstimator</span>
<span class="kn">from</span> <span class="nn">devinterp.slt.mala</span> <span class="kn">import</span> <span class="n">MalaAcceptanceRate</span>
<span class="kn">from</span> <span class="nn">devinterp.slt.norms</span> <span class="kn">import</span> <span class="n">NoiseNorm</span>
<span class="kn">from</span> <span class="nn">devinterp.utils</span> <span class="kn">import</span> <span class="p">(</span>
    <span class="n">EvaluateFn</span><span class="p">,</span>
    <span class="n">get_init_loss_multi_batch</span><span class="p">,</span>
    <span class="n">optimal_temperature</span><span class="p">,</span>
    <span class="n">prepare_input</span><span class="p">,</span>
    <span class="n">split_results</span><span class="p">,</span>
<span class="p">)</span>


<span class="k">def</span> <span class="nf">call_with</span><span class="p">(</span><span class="n">func</span><span class="p">:</span> <span class="n">Callable</span><span class="p">,</span> <span class="o">**</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="c1"># Check the func annotation and call with only the necessary kwargs.</span>
    <span class="n">sig</span> <span class="o">=</span> <span class="n">inspect</span><span class="o">.</span><span class="n">signature</span><span class="p">(</span><span class="n">func</span><span class="p">)</span>

    <span class="c1"># Filter out the kwargs that are not in the function&#39;s signature</span>
    <span class="n">filtered_kwargs</span> <span class="o">=</span> <span class="p">{</span><span class="n">k</span><span class="p">:</span> <span class="n">v</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">kwargs</span><span class="o">.</span><span class="n">items</span><span class="p">()</span> <span class="k">if</span> <span class="n">k</span> <span class="ow">in</span> <span class="n">sig</span><span class="o">.</span><span class="n">parameters</span><span class="p">}</span>

    <span class="c1"># Call the function with the filtered kwargs</span>
    <span class="k">return</span> <span class="n">func</span><span class="p">(</span><span class="o">**</span><span class="n">filtered_kwargs</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">sample_single_chain</span><span class="p">(</span>
    <span class="n">ref_model</span><span class="p">:</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
    <span class="n">evaluate</span><span class="p">:</span> <span class="n">EvaluateFn</span><span class="p">,</span>
    <span class="n">num_draws</span><span class="o">=</span><span class="mi">100</span><span class="p">,</span>
    <span class="n">num_burnin_steps</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
    <span class="n">num_steps_bw_draws</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">grad_accum_steps</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span>
    <span class="n">sampling_method</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">]</span> <span class="o">=</span> <span class="n">SGLD</span><span class="p">,</span>
    <span class="n">optimizer_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">chain</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">int</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">),</span>
    <span class="n">optimize_over_per_model_param</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="nb">dict</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">SamplerCallback</span><span class="p">]</span> <span class="o">=</span> <span class="p">[],</span>
    <span class="n">init_loss</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    
<span class="p">):</span>
    <span class="k">if</span> <span class="n">grad_accum_steps</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="k">assert</span> <span class="nb">type</span><span class="p">(</span><span class="n">grad_accum_steps</span><span class="p">)</span> <span class="o">==</span> <span class="nb">int</span><span class="p">,</span> <span class="s2">&quot;grad_accum_steps must be an integer.&quot;</span>
        <span class="n">num_steps_bw_draws</span> <span class="o">*=</span> <span class="n">grad_accum_steps</span>
        <span class="n">num_burnin_steps</span> <span class="o">*=</span> <span class="n">grad_accum_steps</span>
    <span class="k">if</span> <span class="n">num_draws</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="p">):</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;You are taking more sample batches than there are dataloader batches available, this removes some randomness from sampling but is probably fine. (All sample batches beyond the number dataloader batches are cycled from the start, f.e. 9 samples from [A, B, C] would be [B, A, C, B, A, C, B, A, C].)&quot;</span>
        <span class="p">)</span>
        
    <span class="c1"># Initialize new model and optimizer for this chain</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">deepcopy</span><span class="p">(</span><span class="n">ref_model</span><span class="p">)</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="n">optimizer_kwargs</span> <span class="o">=</span> <span class="n">optimizer_kwargs</span> <span class="ow">or</span> <span class="p">{}</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">callback</span><span class="p">,</span> <span class="n">MalaAcceptanceRate</span><span class="p">)</span> <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="n">callbacks</span><span class="p">):</span>
        <span class="n">optimizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;save_mala_vars&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">callback</span><span class="p">,</span> <span class="n">NoiseNorm</span><span class="p">)</span> <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="n">callbacks</span><span class="p">):</span>
        <span class="n">optimizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;save_noise&quot;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
    <span class="n">optimizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;temperature&quot;</span><span class="p">,</span> <span class="n">optimal_temperature</span><span class="p">(</span><span class="n">loader</span><span class="p">))</span>
    <span class="k">if</span> <span class="n">optimize_over_per_model_param</span><span class="p">:</span>
        <span class="n">param_groups</span> <span class="o">=</span> <span class="p">[]</span>
        <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">parameter</span> <span class="ow">in</span> <span class="n">model</span><span class="o">.</span><span class="n">named_parameters</span><span class="p">():</span>
            <span class="n">param_groups</span><span class="o">.</span><span class="n">append</span><span class="p">(</span>
                <span class="p">{</span>
                    <span class="s2">&quot;params&quot;</span><span class="p">:</span> <span class="n">parameter</span><span class="p">,</span>
                    <span class="s2">&quot;optimize_over&quot;</span><span class="p">:</span> <span class="n">optimize_over_per_model_param</span><span class="p">[</span><span class="n">name</span><span class="p">]</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span>
                <span class="p">}</span>
            <span class="p">)</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">sampling_method</span><span class="p">(</span>
            <span class="n">param_groups</span><span class="p">,</span>
            <span class="o">**</span><span class="n">optimizer_kwargs</span><span class="p">,</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">optimizer</span> <span class="o">=</span> <span class="n">sampling_method</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">parameters</span><span class="p">(),</span> <span class="o">**</span><span class="n">optimizer_kwargs</span><span class="p">)</span>


    <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>

    <span class="n">num_steps</span> <span class="o">=</span> <span class="n">num_draws</span> <span class="o">*</span> <span class="n">num_steps_bw_draws</span> <span class="o">+</span> <span class="n">num_burnin_steps</span>

    <span class="n">cumulative_loss</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">with</span> <span class="n">tqdm</span><span class="p">(</span><span class="n">desc</span><span class="o">=</span><span class="sa">f</span><span class="s2">&quot;Chain </span><span class="si">{</span><span class="n">chain</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">,</span>
        <span class="n">total</span><span class="o">=</span><span class="n">num_steps</span> <span class="o">//</span> <span class="n">grad_accum_steps</span><span class="p">,</span>
        <span class="n">disable</span><span class="o">=</span><span class="ow">not</span> <span class="n">verbose</span><span class="p">)</span> <span class="k">as</span> <span class="n">pbar</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">data</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">num_steps</span><span class="p">),</span> <span class="n">itertools</span><span class="o">.</span><span class="n">cycle</span><span class="p">(</span><span class="n">loader</span><span class="p">)):</span>
            <span class="n">model</span><span class="o">.</span><span class="n">train</span><span class="p">()</span>
            <span class="n">data</span> <span class="o">=</span> <span class="n">prepare_input</span><span class="p">(</span><span class="n">data</span><span class="p">,</span> <span class="n">device</span><span class="p">)</span>

            <span class="n">results</span> <span class="o">=</span> <span class="n">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">)</span>
            <span class="n">loss</span><span class="p">,</span> <span class="n">results</span> <span class="o">=</span> <span class="n">split_results</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">grad_accum_steps</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span> <span class="o">/</span> <span class="n">grad_accum_steps</span>
                <span class="n">cumulative_loss</span> <span class="o">+=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>
            <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

            <span class="c1"># i+1 instead of i so that the gradient accumulates to an entire batch first</span>
            <span class="c1"># otherwise the first draw happens after batch_size/grad_accum_steps samples instead of batch_size samples</span>
            <span class="k">if</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="n">grad_accum_steps</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
                <span class="n">optimizer</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
                <span class="n">pbar</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="mi">1</span><span class="p">)</span>

            <span class="k">if</span> <span class="n">i</span> <span class="o">&gt;=</span> <span class="n">num_burnin_steps</span> <span class="ow">and</span> <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">-</span> <span class="n">num_burnin_steps</span><span class="p">)</span> <span class="o">%</span> <span class="n">num_steps_bw_draws</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
                <span class="n">draw</span> <span class="o">=</span> <span class="p">(</span><span class="n">i</span> <span class="o">-</span> <span class="n">num_burnin_steps</span><span class="p">)</span> <span class="o">//</span> <span class="n">num_steps_bw_draws</span>  <span class="c1"># required for locals()</span>
                <span class="k">if</span> <span class="n">grad_accum_steps</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">cumulative_loss</span>
                    <span class="n">cumulative_loss</span> <span class="o">=</span> <span class="mi">0</span>
                <span class="k">else</span><span class="p">:</span>
                    <span class="n">loss</span> <span class="o">=</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">()</span>

                <span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
                    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="n">callbacks</span><span class="p">:</span>
                        <span class="n">call_with</span><span class="p">(</span><span class="n">callback</span><span class="p">,</span> <span class="o">**</span><span class="nb">locals</span><span class="p">())</span>  <span class="c1"># Cursed. This is the way.</span>


<span class="k">def</span> <span class="nf">_sample_single_chain</span><span class="p">(</span><span class="n">kwargs</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">sample_single_chain</span><span class="p">(</span><span class="o">**</span><span class="n">kwargs</span><span class="p">)</span>


<div class="viewcode-block" id="sample">
<a class="viewcode-back" href="../../../devinterp.slt.html#devinterp.slt.sampler.sample">[docs]</a>
<span class="k">def</span> <span class="nf">sample</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">SamplerCallback</span><span class="p">],</span>
    <span class="n">evaluate</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">EvaluateFn</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sampling_method</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">]</span> <span class="o">=</span> <span class="n">SGLD</span><span class="p">,</span>
    <span class="n">optimizer_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;adaptive&quot;</span><span class="p">]]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_draws</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">num_chains</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">num_burnin_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">num_steps_bw_draws</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">init_loss</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">grad_accum_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">cores</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">),</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">optimize_over_per_model_param</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
<span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Sample model weights using a given sampling_method, supporting multiple chains/cores,</span>
<span class="sd">    and calculate the observables (loss, llc, etc.) for each callback passed along.</span>
<span class="sd">    The :python:`update`, :python:`finalize` and :python:`sample` methods of each :func:`~devinterp.slt.callback.SamplerCallback` are called</span>
<span class="sd">    during sampling, after sampling, and at :python:`sampler_callback_object.sample()` respectively.</span>

<span class="sd">    After calling this function, the stats of interest live in the callback object.</span>

<span class="sd">    :param model: The neural network model.</span>
<span class="sd">    :type model: torch.nn.Module</span>
<span class="sd">    :param loader: DataLoader for input data.</span>
<span class="sd">    :type loader: DataLoader</span>
<span class="sd">    :param evaluate: Maps a model and batch of data to an object with a loss attribute.</span>
<span class="sd">    :type evaluate: EvaluateFn</span>
<span class="sd">    :param callbacks: list of callbacks, each of type SamplerCallback</span>
<span class="sd">    :type callbacks: list[SamplerCallback]</span>
<span class="sd">    :param sampling_method: Sampling method to use (a PyTorch optimizer under the hood). Default is SGLD</span>
<span class="sd">    :type sampling_method: torch.optim.Optimizer, optional</span>
<span class="sd">    :param optimizer_kwargs: Keyword arguments for the PyTorch optimizer (used as sampler here). Default is None (using standard SGLD parameters as defined in the SGLD class)</span>
<span class="sd">    :type optimizer_kwargs: dict, optional</span>
<span class="sd">    :param num_draws: Number of samples to draw. Default is 100</span>
<span class="sd">    :type num_draws: int, optional</span>
<span class="sd">    :param num_chains: Number of chains to run. Default is 10</span>
<span class="sd">    :type num_chains: int, optional</span>
<span class="sd">    :param num_burnin_steps: Number of burn-in steps before sampling. Default is 0</span>
<span class="sd">    :type num_burnin_steps: int, optional</span>
<span class="sd">    :param num_steps_bw_draws: Number of steps between each draw. Default is 1</span>
<span class="sd">    :type num_steps_bw_draws: int, optional</span>
<span class="sd">    :param init_loss: Initial loss for use in `LLCEstimator` and `OnlineLLCEstimator`</span>
<span class="sd">    :type init_loss: float, optional</span>
<span class="sd">    :param cores: Number of cores for parallel execution. Default is 1</span>
<span class="sd">    :type cores: int, optional</span>
<span class="sd">    :param seed: Random seed(s) for sampling. Each chain gets a different (deterministic) seed if this is passed. Default is None</span>
<span class="sd">    :type seed: int, optional</span>
<span class="sd">    :param device: Device to perform computations on, e.g., &#39;cpu&#39; or &#39;cuda&#39;. Default is &#39;cpu&#39;</span>
<span class="sd">    :type device: str or torch.device, optional</span>
<span class="sd">    :param verbose: whether to print sample chain progress. Default is True</span>
<span class="sd">    :type verbose: bool, optional</span>

<span class="sd">    :raises ValueError: if derivative callbacks (f.e. :func:`~devinterp.slt.loss.OnlineLossStatistics`) are passed before base callbacks (f.e. :func:`~devinterp.slt.llc.OnlineLLCEstimator`)</span>
<span class="sd">    :raises Warning: if num_burnin_steps &lt; num_draws</span>
<span class="sd">    :raises Warning: if num_draws &gt; len(loader)</span>
<span class="sd">    :raises Warning: if using seeded runs</span>

<span class="sd">    :returns: None (access LLCs or other observables through `callback_object.sample()`)</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="k">if</span> <span class="n">num_burnin_steps</span> <span class="o">&lt;</span> <span class="n">num_draws</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;You are taking more draws than burn-in steps, your LLC estimates will likely be underestimates. Please check LLC chain convergence.&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="n">num_draws</span> <span class="o">&gt;</span> <span class="nb">len</span><span class="p">(</span><span class="n">loader</span><span class="p">):</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;You are taking more sample batches than there are dataloader batches available, &quot;</span>
            <span class="s2">&quot;this removes some randomness from sampling but is probably fine. (All sample batches &quot;</span>
            <span class="s2">&quot;beyond the number dataloader batches are cycled from the start, f.e. 9 samples from [A, B, C] would be [B, A, C, B, A, C, B, A, C].)&quot;</span>
        <span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">init_loss</span><span class="p">:</span>
        <span class="n">init_loss</span> <span class="o">=</span> <span class="n">get_init_loss_multi_batch</span><span class="p">(</span>
            <span class="n">loader</span><span class="p">,</span> <span class="n">num_chains</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">evaluate</span><span class="p">,</span> <span class="n">device</span>
        <span class="p">)</span>
        <span class="c1"># alternative: init_loss = get_init_loss_full_batch(loader, model, evaluate, device)</span>
        <span class="c1"># alternative: init_loss = get_init_loss_one_batch(loader, model, evaluate, device)</span>
    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="n">callbacks</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">callback</span><span class="p">,</span> <span class="p">(</span><span class="n">OnlineLLCEstimator</span><span class="p">,</span> <span class="n">LLCEstimator</span><span class="p">)):</span>
            <span class="nb">setattr</span><span class="p">(</span><span class="n">callback</span><span class="p">,</span> <span class="s2">&quot;init_loss&quot;</span><span class="p">,</span> <span class="n">init_loss</span><span class="p">)</span>

    <span class="k">if</span> <span class="n">cores</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">cores</span> <span class="o">=</span> <span class="nb">min</span><span class="p">(</span><span class="mi">4</span><span class="p">,</span> <span class="n">cpu_count</span><span class="p">())</span>

    <span class="k">if</span> <span class="n">seed</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
        <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
            <span class="s2">&quot;You are using seeded runs, for full reproducibility check https://pytorch.org/docs/stable/notes/randomness.html&quot;</span>
        <span class="p">)</span>
        <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">seed</span><span class="p">,</span> <span class="nb">int</span><span class="p">):</span>
            <span class="n">seeds</span> <span class="o">=</span> <span class="p">[</span><span class="n">seed</span> <span class="o">+</span> <span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_chains</span><span class="p">)]</span>
        <span class="k">elif</span> <span class="nb">len</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span> <span class="o">!=</span> <span class="n">num_chains</span><span class="p">:</span>
            <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Length of seed list must match number of chains&quot;</span><span class="p">)</span>
        <span class="k">else</span><span class="p">:</span>
            <span class="n">seeds</span> <span class="o">=</span> <span class="n">seed</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">seeds</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="n">num_chains</span>

    <span class="k">if</span> <span class="n">evaluate</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>

        <span class="k">def</span> <span class="nf">evaluate</span><span class="p">(</span><span class="n">model</span><span class="p">,</span> <span class="n">data</span><span class="p">):</span>
            <span class="k">return</span> <span class="n">model</span><span class="p">(</span><span class="n">data</span><span class="p">)</span>

    <span class="n">validate_callbacks</span><span class="p">(</span><span class="n">callbacks</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">get_args</span><span class="p">(</span><span class="n">i</span><span class="p">):</span>
        <span class="k">return</span> <span class="nb">dict</span><span class="p">(</span>
            <span class="n">chain</span><span class="o">=</span><span class="n">i</span><span class="p">,</span>
            <span class="n">seed</span><span class="o">=</span><span class="n">seeds</span><span class="p">[</span><span class="n">i</span><span class="p">],</span>
            <span class="n">ref_model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
            <span class="n">loader</span><span class="o">=</span><span class="n">loader</span><span class="p">,</span>
            <span class="n">evaluate</span><span class="o">=</span><span class="n">evaluate</span><span class="p">,</span>
            <span class="n">num_draws</span><span class="o">=</span><span class="n">num_draws</span><span class="p">,</span>
            <span class="n">num_burnin_steps</span><span class="o">=</span><span class="n">num_burnin_steps</span><span class="p">,</span>
            <span class="n">num_steps_bw_draws</span><span class="o">=</span><span class="n">num_steps_bw_draws</span><span class="p">,</span>
            <span class="n">init_loss</span><span class="o">=</span><span class="n">init_loss</span><span class="p">,</span>
            <span class="n">grad_accum_steps</span><span class="o">=</span><span class="n">grad_accum_steps</span><span class="p">,</span>
            <span class="n">sampling_method</span><span class="o">=</span><span class="n">sampling_method</span><span class="p">,</span>
            <span class="n">optimizer_kwargs</span><span class="o">=</span><span class="n">optimizer_kwargs</span><span class="p">,</span>
            <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
            <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
            <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
            <span class="n">optimize_over_per_model_param</span><span class="o">=</span><span class="n">optimize_over_per_model_param</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">if</span> <span class="n">cores</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
        <span class="n">ctx</span> <span class="o">=</span> <span class="n">get_context</span><span class="p">(</span><span class="s2">&quot;spawn&quot;</span><span class="p">)</span>
        <span class="k">with</span> <span class="n">ctx</span><span class="o">.</span><span class="n">Pool</span><span class="p">(</span><span class="n">cores</span><span class="p">)</span> <span class="k">as</span> <span class="n">pool</span><span class="p">:</span>
            <span class="n">pool</span><span class="o">.</span><span class="n">map</span><span class="p">(</span><span class="n">_sample_single_chain</span><span class="p">,</span> <span class="p">[</span><span class="n">get_args</span><span class="p">(</span><span class="n">i</span><span class="p">)</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_chains</span><span class="p">)])</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">num_chains</span><span class="p">):</span>
            <span class="n">_sample_single_chain</span><span class="p">(</span><span class="n">get_args</span><span class="p">(</span><span class="n">i</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="n">callbacks</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">callback</span><span class="p">,</span> <span class="s2">&quot;finalize&quot;</span><span class="p">):</span>
            <span class="n">callback</span><span class="o">.</span><span class="n">finalize</span><span class="p">()</span></div>



<span class="k">def</span> <span class="nf">estimate_learning_coeff_with_summary</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="p">[],</span>
    <span class="n">evaluate</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">EvaluateFn</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sampling_method</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">]</span> <span class="o">=</span> <span class="n">SGLD</span><span class="p">,</span>
    <span class="n">optimizer_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;adaptive&quot;</span><span class="p">]]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_draws</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">num_chains</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">num_burnin_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">num_steps_bw_draws</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">init_loss</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">grad_accum_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">cores</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">),</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">optimize_over_per_model_param</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">online</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">dict</span><span class="p">:</span>
    <span class="n">optimizer_kwargs</span><span class="o">.</span><span class="n">setdefault</span><span class="p">(</span><span class="s2">&quot;temperature&quot;</span><span class="p">,</span> <span class="n">optimal_temperature</span><span class="p">(</span><span class="n">loader</span><span class="p">))</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">init_loss</span><span class="p">:</span>
        <span class="n">init_loss</span> <span class="o">=</span> <span class="n">get_init_loss_multi_batch</span><span class="p">(</span>
            <span class="n">loader</span><span class="p">,</span> <span class="n">num_chains</span><span class="p">,</span> <span class="n">model</span><span class="p">,</span> <span class="n">evaluate</span><span class="p">,</span> <span class="n">device</span>
        <span class="p">)</span>
        <span class="c1"># alternative: init_loss = get_init_loss_full_batch(loader, model, evaluate, device)</span>
        <span class="c1"># alternative: init_loss = get_init_loss_one_batch(loader, model, evaluate, device)</span>
    <span class="k">if</span> <span class="n">online</span><span class="p">:</span>
        <span class="n">llc_estimator</span> <span class="o">=</span> <span class="n">OnlineLLCEstimator</span><span class="p">(</span>
            <span class="n">num_chains</span><span class="p">,</span> <span class="n">num_draws</span><span class="p">,</span> <span class="n">optimizer_kwargs</span><span class="p">[</span><span class="s2">&quot;temperature&quot;</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span>
        <span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">llc_estimator</span> <span class="o">=</span> <span class="n">LLCEstimator</span><span class="p">(</span>
            <span class="n">num_chains</span><span class="p">,</span> <span class="n">num_draws</span><span class="p">,</span> <span class="n">optimizer_kwargs</span><span class="p">[</span><span class="s2">&quot;temperature&quot;</span><span class="p">],</span> <span class="n">device</span><span class="o">=</span><span class="n">device</span>
        <span class="p">)</span>

    <span class="n">callbacks</span> <span class="o">=</span> <span class="p">[</span><span class="n">llc_estimator</span><span class="p">,</span> <span class="o">*</span><span class="n">callbacks</span><span class="p">]</span>

    <span class="n">sample</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">loader</span><span class="o">=</span><span class="n">loader</span><span class="p">,</span>
        <span class="n">evaluate</span><span class="o">=</span><span class="n">evaluate</span><span class="p">,</span>
        <span class="n">sampling_method</span><span class="o">=</span><span class="n">sampling_method</span><span class="p">,</span>
        <span class="n">optimizer_kwargs</span><span class="o">=</span><span class="n">optimizer_kwargs</span><span class="p">,</span>
        <span class="n">num_draws</span><span class="o">=</span><span class="n">num_draws</span><span class="p">,</span>
        <span class="n">num_chains</span><span class="o">=</span><span class="n">num_chains</span><span class="p">,</span>
        <span class="n">num_burnin_steps</span><span class="o">=</span><span class="n">num_burnin_steps</span><span class="p">,</span>
        <span class="n">num_steps_bw_draws</span><span class="o">=</span><span class="n">num_steps_bw_draws</span><span class="p">,</span>
        <span class="n">grad_accum_steps</span><span class="o">=</span><span class="n">grad_accum_steps</span><span class="p">,</span>
        <span class="n">cores</span><span class="o">=</span><span class="n">cores</span><span class="p">,</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
        <span class="n">init_loss</span><span class="o">=</span><span class="n">init_loss</span><span class="p">,</span>
        <span class="n">optimize_over_per_model_param</span><span class="o">=</span><span class="n">optimize_over_per_model_param</span><span class="p">,</span>
    <span class="p">)</span>

    <span class="n">results</span> <span class="o">=</span> <span class="p">{}</span>

    <span class="k">for</span> <span class="n">callback</span> <span class="ow">in</span> <span class="n">callbacks</span><span class="p">:</span>
        <span class="k">if</span> <span class="nb">hasattr</span><span class="p">(</span><span class="n">callback</span><span class="p">,</span> <span class="s2">&quot;sample&quot;</span><span class="p">):</span>
            <span class="n">results</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">callback</span><span class="o">.</span><span class="n">sample</span><span class="p">())</span>

    <span class="k">return</span> <span class="n">results</span>


<span class="k">def</span> <span class="nf">estimate_learning_coeff</span><span class="p">(</span>
    <span class="n">model</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">,</span>
    <span class="n">loader</span><span class="p">:</span> <span class="n">DataLoader</span><span class="p">,</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span><span class="p">[</span><span class="n">Callable</span><span class="p">]</span> <span class="o">=</span> <span class="p">[],</span>
    <span class="n">evaluate</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">EvaluateFn</span><span class="p">]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">sampling_method</span><span class="p">:</span> <span class="n">Type</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">Optimizer</span><span class="p">]</span> <span class="o">=</span> <span class="n">SGLD</span><span class="p">,</span>
    <span class="n">optimizer_kwargs</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">Union</span><span class="p">[</span><span class="nb">float</span><span class="p">,</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;adaptive&quot;</span><span class="p">]]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">num_draws</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">100</span><span class="p">,</span>
    <span class="n">num_chains</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span>
    <span class="n">num_burnin_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span>
    <span class="n">num_steps_bw_draws</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">init_loss</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">grad_accum_steps</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">cores</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span>
    <span class="n">seed</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Union</span><span class="p">[</span><span class="nb">int</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">int</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">Union</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="nb">str</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="s2">&quot;cpu&quot;</span><span class="p">),</span>
    <span class="n">verbose</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">optimize_over_per_model_param</span><span class="p">:</span> <span class="n">Optional</span><span class="p">[</span><span class="n">Dict</span><span class="p">[</span><span class="nb">str</span><span class="p">,</span> <span class="n">List</span><span class="p">[</span><span class="nb">bool</span><span class="p">]]]</span> <span class="o">=</span> <span class="kc">None</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">float</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">estimate_learning_coeff_with_summary</span><span class="p">(</span>
        <span class="n">model</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
        <span class="n">loader</span><span class="o">=</span><span class="n">loader</span><span class="p">,</span>
        <span class="n">evaluate</span><span class="o">=</span><span class="n">evaluate</span><span class="p">,</span>
        <span class="n">sampling_method</span><span class="o">=</span><span class="n">sampling_method</span><span class="p">,</span>
        <span class="n">optimizer_kwargs</span><span class="o">=</span><span class="n">optimizer_kwargs</span><span class="p">,</span>
        <span class="n">num_draws</span><span class="o">=</span><span class="n">num_draws</span><span class="p">,</span>
        <span class="n">num_chains</span><span class="o">=</span><span class="n">num_chains</span><span class="p">,</span>
        <span class="n">num_burnin_steps</span><span class="o">=</span><span class="n">num_burnin_steps</span><span class="p">,</span>
        <span class="n">num_steps_bw_draws</span><span class="o">=</span><span class="n">num_steps_bw_draws</span><span class="p">,</span>
        <span class="n">grad_accum_steps</span><span class="o">=</span><span class="n">grad_accum_steps</span><span class="p">,</span>
        <span class="n">cores</span><span class="o">=</span><span class="n">cores</span><span class="p">,</span>
        <span class="n">seed</span><span class="o">=</span><span class="n">seed</span><span class="p">,</span>
        <span class="n">device</span><span class="o">=</span><span class="n">device</span><span class="p">,</span>
        <span class="n">verbose</span><span class="o">=</span><span class="n">verbose</span><span class="p">,</span>
        <span class="n">callbacks</span><span class="o">=</span><span class="n">callbacks</span><span class="p">,</span>
        <span class="n">online</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">init_loss</span><span class="o">=</span><span class="n">init_loss</span><span class="p">,</span>
        <span class="n">optimize_over_per_model_param</span><span class="o">=</span><span class="n">optimize_over_per_model_param</span><span class="p">,</span>
    <span class="p">)[</span><span class="s2">&quot;llc/mean&quot;</span><span class="p">]</span>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2024, Van Wingerden et al..</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>