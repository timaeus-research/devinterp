{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grokking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Optional, Any\n",
    "import logging\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F\n",
    "from tqdm.notebook import trange, tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from devinterp.zoo.arithmetic import ModularArithmeticConfig, ModularArithmetic\n",
    "from devinterp.zoo.transformer import TransformerConfig, Transformer\n",
    "from devinterp.utils import get_default_device\n",
    "from devinterp.data import Reduction\n",
    "from devinterp.slt.sampler import estimate_rlct\n",
    "from devinterp.evals import CombineEvaluators, Evaluator, RepeatEvaluator\n",
    "from devinterp.optim.schedulers import LRScheduler\n",
    "\n",
    "\n",
    "device = get_default_device()\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "\n",
    "MODULUS = 113\n",
    "\n",
    "trainset, testset = ModularArithmeticConfig(\n",
    "    operator=\"/\",\n",
    "    modulus=MODULUS,\n",
    "    seed=0,\n",
    "    split=0.4\n",
    ").factory_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evals\n",
    "\n",
    "def cross_entropy_last_token(outputs, targets, reduction: Reduction = \"sum\"):\n",
    "    \"\"\"\n",
    "    Wrapper around cross entropy loss because we only care about the last number predicted.\n",
    "    \"\"\"\n",
    "    # Only look at predictions of last numbers\n",
    "    outputs = outputs[:, -1]\n",
    "\n",
    "    # Compute individual and summed losses for final number\n",
    "    logprobs = F.log_softmax(outputs.to(torch.float32), dim=-1)\n",
    "    prediction_logprobs = torch.gather(logprobs, index=targets.unsqueeze(1), dim=-1)\n",
    "\n",
    "    if reduction == \"mean\":\n",
    "        loss = -torch.mean(prediction_logprobs)\n",
    "    elif reduction == \"sum\":\n",
    "        loss = -torch.sum(prediction_logprobs)\n",
    "    else:\n",
    "        raise ValueError(\"Invalid reduction argument.\")\n",
    "\n",
    "    return loss\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=1024, shuffle=True)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=1024, shuffle=False)\n",
    "\n",
    "\n",
    "def eval_loss_and_acc(model: nn.Module, *_) -> Dict[str, float]:\n",
    "    model.eval()\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for name, loader in zip([\"train\", \"test\"], [trainloader, testloader]):\n",
    "        total = 0\n",
    "        correct = 0\n",
    "\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "\n",
    "            with torch.no_grad():\n",
    "                y_hat = model(x)\n",
    "\n",
    "            total += cross_entropy_last_token(y_hat, y, reduction=\"sum\").item()\n",
    "            correct += (y_hat[:, -1, :].max(dim=1).indices == y).sum().item()  # argmax doesn't work for device=mps\n",
    "\n",
    "        results[f\"{name}/loss\"] = total / len(loader.dataset)\n",
    "        results[f\"{name}/accuracy\"] = correct / len(loader.dataset)\n",
    "\n",
    "    return results\n",
    "\n",
    "\n",
    "def eval_rlct(model: nn.Module, *_):\n",
    "    optimizer_kwargs = dict(\n",
    "        lr=1e-7, noise_level=1., weight_decay=3e-7, elasticity=10., temperature=\"adaptive\", num_samples=len(trainset)\n",
    "    )\n",
    "    return {\n",
    "        \"rlct\": estimate_rlct(model, trainloader, cross_entropy_last_token, 'sgld', optimizer_kwargs, num_draws=20, num_chains=5, num_burnin_steps=0, num_steps_bw_draws=1, cores=1, pbar=False)\n",
    "    }\n",
    "\n",
    "\n",
    "evals = CombineEvaluators([\n",
    "    eval_loss_and_acc,\n",
    "    RepeatEvaluator(eval_rlct, 5),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Jesse/Projects/devinterp/devinterp/utils.py:46: UserWarning: Number of steps in int_logspace is not 25, got 24.\n",
      "  warnings.warn(\n",
      "INFO:devinterp.learner:Logging to wandb disabled\n",
      "INFO:devinterp.learner:batch_size: 256\n",
      "checkpointer_config:\n",
      "  bucket_name: null\n",
      "  device: cpu\n",
      "  local_root: ../\n",
      "  project_dir: div-mod-113\n",
      "criterion: cross_entropy\n",
      "device: mps\n",
      "logger_config:\n",
      "  entity: null\n",
      "  out_file: null\n",
      "  project: null\n",
      "  run_id: null\n",
      "  stdout: false\n",
      "  use_df: false\n",
      "num_steps: 25000\n",
      "num_training_samples: 5107\n",
      "optimizer_config:\n",
      "  betas: !!python/tuple\n",
      "  - 0.9\n",
      "  - 0.98\n",
      "  elasticity: null\n",
      "  lr: 0.001\n",
      "  momentum: null\n",
      "  noise_level: null\n",
      "  num_samples: null\n",
      "  optimizer_type: AdamW\n",
      "  temperature: null\n",
      "  weight_decay: 0.2\n",
      "scheduler_config: null\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from devinterp.learner import LearnerConfig\n",
    "\n",
    "model_config = TransformerConfig(d_vocab=MODULUS + 1)\n",
    "model = model_config.factory().to(device)\n",
    "\n",
    "learner_config = LearnerConfig(\n",
    "    num_training_samples=len(trainset),\n",
    "    batch_size=256,\n",
    "    num_steps=25_000,\n",
    "    criterion=\"cross_entropy\",\n",
    "    device=device,\n",
    "    optimizer_config={\n",
    "        \"optimizer_type\": \"AdamW\",\n",
    "        \"lr\": 1e-3,\n",
    "        \"weight_decay\": 0.2,\n",
    "        \"betas\": (0.9, 0.98),\n",
    "    },\n",
    "    logger_config={\n",
    "        # \"project\": \"grokking\",\n",
    "        # \"entity\": \"devinterp\",\n",
    "        \"logging_steps\": {\n",
    "            \"log_space\": 25,\n",
    "            \"linear_space\": 100,\n",
    "        },\n",
    "        \"use_std\": True\n",
    "   },\n",
    "   checkpointer_config={\n",
    "        \"checkpoint_steps\": {\n",
    "            \"log_space\": 25,\n",
    "            \"linear_space\": 100,\n",
    "        },\n",
    "        # \"bucket\": \"devinterp\",\n",
    "        \"project_dir\": \"div-mod-113\",\n",
    "        \"local_root\": \"../\"\n",
    "   },\n",
    ")\n",
    "\n",
    "learner = learner_config.factory(\n",
    "    model=model,\n",
    "    dataset=trainset,\n",
    "    evaluator=evals\n",
    ")\n",
    "learner.criterion = cross_entropy_last_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "54889d7d5e2a4b2fb7b7f8f36d228471",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training...:   0%|          | 0/25000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False False False\n",
      "False None\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "element 0 of tensors does not require grad and does not have a grad_fn",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# learner.save_checkpoint(0)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m learner\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/Projects/devinterp/devinterp/learner.py:158\u001b[0m, in \u001b[0;36mLearner.train\u001b[0;34m(self, resume, verbose)\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39meval()\n\u001b[1;32m    156\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad():\n\u001b[1;32m    157\u001b[0m     evals \u001b[39m=\u001b[39m (\n\u001b[0;32m--> 158\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluator(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptimizer, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mscheduler)\n\u001b[1;32m    159\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluator\n\u001b[1;32m    160\u001b[0m         \u001b[39melse\u001b[39;00m {\u001b[39m\"\u001b[39m\u001b[39mBatch/Loss\u001b[39m\u001b[39m\"\u001b[39m: loss\u001b[39m.\u001b[39mitem()}\n\u001b[1;32m    161\u001b[0m     )\n\u001b[1;32m    162\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlogger\u001b[39m.\u001b[39mlog(evals, step\u001b[39m=\u001b[39mstep)\n\u001b[1;32m    164\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel\u001b[39m.\u001b[39mtrain()\n",
      "File \u001b[0;32m~/Projects/devinterp/devinterp/evals.py:184\u001b[0m, in \u001b[0;36mCombineEvaluators.__call__\u001b[0;34m(self, model, optimizer, scheduler)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    173\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    174\u001b[0m     model: nn\u001b[39m.\u001b[39mModule,\n\u001b[1;32m    175\u001b[0m     optimizer: torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mOptimizer,\n\u001b[1;32m    176\u001b[0m     scheduler: Optional[LRScheduler],\n\u001b[1;32m    177\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m    178\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Applies all evaluation methods and combines their results.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \n\u001b[1;32m    180\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[39m        Dict: Combined dictionary of evaluation metrics from all evaluation methods.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 184\u001b[0m     \u001b[39mreturn\u001b[39;00m functools\u001b[39m.\u001b[39;49mreduce(\n\u001b[1;32m    185\u001b[0m         \u001b[39mlambda\u001b[39;49;00m x, y: x \u001b[39m|\u001b[39;49m y,\n\u001b[1;32m    186\u001b[0m         (\n\u001b[1;32m    187\u001b[0m             run_and_clean_evals(eval_, model, optimizer, scheduler)\n\u001b[1;32m    188\u001b[0m             \u001b[39mfor\u001b[39;49;00m eval_ \u001b[39min\u001b[39;49;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevals\n\u001b[1;32m    189\u001b[0m         ),\n\u001b[1;32m    190\u001b[0m         {},\n\u001b[1;32m    191\u001b[0m     )\n",
      "File \u001b[0;32m~/Projects/devinterp/devinterp/evals.py:187\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\n\u001b[1;32m    173\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    174\u001b[0m     model: nn\u001b[39m.\u001b[39mModule,\n\u001b[1;32m    175\u001b[0m     optimizer: torch\u001b[39m.\u001b[39moptim\u001b[39m.\u001b[39mOptimizer,\n\u001b[1;32m    176\u001b[0m     scheduler: Optional[LRScheduler],\n\u001b[1;32m    177\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Dict[\u001b[39mstr\u001b[39m, Any]:\n\u001b[1;32m    178\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Applies all evaluation methods and combines their results.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \n\u001b[1;32m    180\u001b[0m \u001b[39m    Returns:\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[39m        Dict: Combined dictionary of evaluation metrics from all evaluation methods.\u001b[39;00m\n\u001b[1;32m    182\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m    184\u001b[0m     \u001b[39mreturn\u001b[39;00m functools\u001b[39m.\u001b[39mreduce(\n\u001b[1;32m    185\u001b[0m         \u001b[39mlambda\u001b[39;00m x, y: x \u001b[39m|\u001b[39m y,\n\u001b[1;32m    186\u001b[0m         (\n\u001b[0;32m--> 187\u001b[0m             run_and_clean_evals(eval_, model, optimizer, scheduler)\n\u001b[1;32m    188\u001b[0m             \u001b[39mfor\u001b[39;00m eval_ \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevals\n\u001b[1;32m    189\u001b[0m         ),\n\u001b[1;32m    190\u001b[0m         {},\n\u001b[1;32m    191\u001b[0m     )\n",
      "File \u001b[0;32m~/Projects/devinterp/devinterp/evals.py:159\u001b[0m, in \u001b[0;36mrun_and_clean_evals\u001b[0;34m(eval_, model, optimizer, scheduler)\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_and_clean_evals\u001b[39m(eval_: Evaluator, model, optimizer\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, scheduler\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m--> 159\u001b[0m     \u001b[39mreturn\u001b[39;00m clean_evals_results(run_eval(eval_, model, optimizer, scheduler))\n",
      "File \u001b[0;32m~/Projects/devinterp/devinterp/evals.py:151\u001b[0m, in \u001b[0;36mrun_eval\u001b[0;34m(eval_, model, optimizer, scheduler)\u001b[0m\n\u001b[1;32m    149\u001b[0m     result \u001b[39m=\u001b[39m eval_(model, optimizer)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39melif\u001b[39;00m num_params \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:  \u001b[39m# ModelOptimizerSchedulerEvaluator\u001b[39;00m\n\u001b[0;32m--> 151\u001b[0m     result \u001b[39m=\u001b[39m eval_(model, optimizer, scheduler)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    152\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    153\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mUnknown Evaluator with \u001b[39m\u001b[39m{\u001b[39;00mnum_params\u001b[39m}\u001b[39;00m\u001b[39m parameters.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Projects/devinterp/devinterp/evals.py:216\u001b[0m, in \u001b[0;36mRepeatEvaluator.__call__\u001b[0;34m(self, model, optimizer, scheduler)\u001b[0m\n\u001b[1;32m    213\u001b[0m results \u001b[39m=\u001b[39m {}\n\u001b[1;32m    215\u001b[0m \u001b[39mfor\u001b[39;00m _ \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_repeats):\n\u001b[0;32m--> 216\u001b[0m     result \u001b[39m=\u001b[39m run_eval(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49meval_, model, optimizer, scheduler)\n\u001b[1;32m    217\u001b[0m     \u001b[39mfor\u001b[39;00m key, value \u001b[39min\u001b[39;00m result\u001b[39m.\u001b[39mitems():\n\u001b[1;32m    218\u001b[0m         \u001b[39mif\u001b[39;00m key \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m results:\n",
      "File \u001b[0;32m~/Projects/devinterp/devinterp/evals.py:149\u001b[0m, in \u001b[0;36mrun_eval\u001b[0;34m(eval_, model, optimizer, scheduler)\u001b[0m\n\u001b[1;32m    147\u001b[0m     result \u001b[39m=\u001b[39m eval_(model)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    148\u001b[0m \u001b[39melif\u001b[39;00m num_params \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m:  \u001b[39m# ModelOptimizerEvaluator\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m     result \u001b[39m=\u001b[39m eval_(model, optimizer)  \u001b[39m# type: ignore\u001b[39;00m\n\u001b[1;32m    150\u001b[0m \u001b[39melif\u001b[39;00m num_params \u001b[39m==\u001b[39m \u001b[39m3\u001b[39m:  \u001b[39m# ModelOptimizerSchedulerEvaluator\u001b[39;00m\n\u001b[1;32m    151\u001b[0m     result \u001b[39m=\u001b[39m eval_(model, optimizer, scheduler)  \u001b[39m# type: ignore\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[5], line 57\u001b[0m, in \u001b[0;36meval_rlct\u001b[0;34m(model, *_)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39meval_rlct\u001b[39m(model: nn\u001b[39m.\u001b[39mModule, \u001b[39m*\u001b[39m_):\n\u001b[1;32m     53\u001b[0m     optimizer_kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[1;32m     54\u001b[0m         lr\u001b[39m=\u001b[39m\u001b[39m1e-7\u001b[39m, noise_level\u001b[39m=\u001b[39m\u001b[39m1.\u001b[39m, weight_decay\u001b[39m=\u001b[39m\u001b[39m3e-7\u001b[39m, elasticity\u001b[39m=\u001b[39m\u001b[39m10.\u001b[39m, temperature\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39madaptive\u001b[39m\u001b[39m\"\u001b[39m, num_samples\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(trainset)\n\u001b[1;32m     55\u001b[0m     )\n\u001b[1;32m     56\u001b[0m     \u001b[39mreturn\u001b[39;00m {\n\u001b[0;32m---> 57\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mrlct\u001b[39m\u001b[39m\"\u001b[39m: estimate_rlct(model, trainloader, cross_entropy_last_token, \u001b[39m'\u001b[39;49m\u001b[39msgld\u001b[39;49m\u001b[39m'\u001b[39;49m, optimizer_kwargs, num_draws\u001b[39m=\u001b[39;49m\u001b[39m20\u001b[39;49m, num_chains\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, num_burnin_steps\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m, num_steps_bw_draws\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, cores\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m, pbar\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[1;32m     58\u001b[0m     }\n",
      "File \u001b[0;32m~/Projects/devinterp/devinterp/slt/sampler.py:169\u001b[0m, in \u001b[0;36mestimate_rlct\u001b[0;34m(model, loader, criterion, step, optimizer_kwargs, num_draws, num_chains, num_burnin_steps, num_steps_bw_draws, cores, seed, pbar, baseline, device)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mestimate_rlct\u001b[39m(\n\u001b[1;32m    154\u001b[0m     model: torch\u001b[39m.\u001b[39mnn\u001b[39m.\u001b[39mModule,\n\u001b[1;32m    155\u001b[0m     loader: DataLoader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    167\u001b[0m     device: torch\u001b[39m.\u001b[39mdevice \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m    168\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[0;32m--> 169\u001b[0m     trace \u001b[39m=\u001b[39m sample(\n\u001b[1;32m    170\u001b[0m         model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    171\u001b[0m         loader\u001b[39m=\u001b[39;49mloader,\n\u001b[1;32m    172\u001b[0m         criterion\u001b[39m=\u001b[39;49mcriterion,\n\u001b[1;32m    173\u001b[0m         step\u001b[39m=\u001b[39;49mstep,\n\u001b[1;32m    174\u001b[0m         optimizer_kwargs\u001b[39m=\u001b[39;49moptimizer_kwargs,\n\u001b[1;32m    175\u001b[0m         num_draws\u001b[39m=\u001b[39;49mnum_draws,\n\u001b[1;32m    176\u001b[0m         num_chains\u001b[39m=\u001b[39;49mnum_chains,\n\u001b[1;32m    177\u001b[0m         num_burnin_steps\u001b[39m=\u001b[39;49mnum_burnin_steps,\n\u001b[1;32m    178\u001b[0m         num_steps_bw_draws\u001b[39m=\u001b[39;49mnum_steps_bw_draws,\n\u001b[1;32m    179\u001b[0m         cores\u001b[39m=\u001b[39;49mcores,\n\u001b[1;32m    180\u001b[0m         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[1;32m    181\u001b[0m         pbar\u001b[39m=\u001b[39;49mpbar,\n\u001b[1;32m    182\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    183\u001b[0m     )\n\u001b[1;32m    185\u001b[0m     \u001b[39mif\u001b[39;00m baseline \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39minit\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[1;32m    186\u001b[0m         baseline_loss \u001b[39m=\u001b[39m trace\u001b[39m.\u001b[39mloc[trace[\u001b[39m\"\u001b[39m\u001b[39mchain\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mloss\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39miloc[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/Projects/devinterp/devinterp/slt/sampler.py:147\u001b[0m, in \u001b[0;36msample\u001b[0;34m(model, loader, criterion, step, optimizer_kwargs, num_draws, num_chains, num_burnin_steps, num_steps_bw_draws, cores, seed, pbar, device)\u001b[0m\n\u001b[1;32m    144\u001b[0m results \u001b[39m=\u001b[39m []\n\u001b[1;32m    146\u001b[0m \u001b[39mfor\u001b[39;00m chain, seed \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(\u001b[39mrange\u001b[39m(num_chains), seeds):\n\u001b[0;32m--> 147\u001b[0m     results\u001b[39m.\u001b[39mappend(_sample_single_chain((chain, seed)))\n\u001b[1;32m    149\u001b[0m results_df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mconcat(results, ignore_index\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m    150\u001b[0m \u001b[39mreturn\u001b[39;00m results_df\n",
      "File \u001b[0;32m~/Projects/devinterp/devinterp/slt/sampler.py:126\u001b[0m, in \u001b[0;36msample.<locals>._sample_single_chain\u001b[0;34m(chain_seed)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_sample_single_chain\u001b[39m(chain_seed):\n\u001b[0;32m--> 126\u001b[0m     \u001b[39mreturn\u001b[39;00m sample_single_chain(\n\u001b[1;32m    127\u001b[0m         chain\u001b[39m=\u001b[39;49mchain_seed[\u001b[39m0\u001b[39;49m],\n\u001b[1;32m    128\u001b[0m         seed\u001b[39m=\u001b[39;49mchain_seed[\u001b[39m1\u001b[39;49m],\n\u001b[1;32m    129\u001b[0m         ref_model\u001b[39m=\u001b[39;49mmodel,\n\u001b[1;32m    130\u001b[0m         loader\u001b[39m=\u001b[39;49mloader,\n\u001b[1;32m    131\u001b[0m         criterion\u001b[39m=\u001b[39;49mcriterion,\n\u001b[1;32m    132\u001b[0m         num_draws\u001b[39m=\u001b[39;49mnum_draws,\n\u001b[1;32m    133\u001b[0m         num_burnin_steps\u001b[39m=\u001b[39;49mnum_burnin_steps,\n\u001b[1;32m    134\u001b[0m         num_steps_bw_draws\u001b[39m=\u001b[39;49mnum_steps_bw_draws,\n\u001b[1;32m    135\u001b[0m         step\u001b[39m=\u001b[39;49mstep,\n\u001b[1;32m    136\u001b[0m         optimizer_kwargs\u001b[39m=\u001b[39;49moptimizer_kwargs,\n\u001b[1;32m    137\u001b[0m         pbar\u001b[39m=\u001b[39;49mpbar,\n\u001b[1;32m    138\u001b[0m         device\u001b[39m=\u001b[39;49mdevice,\n\u001b[1;32m    139\u001b[0m     )\n",
      "File \u001b[0;32m~/Projects/devinterp/devinterp/slt/sampler.py:67\u001b[0m, in \u001b[0;36msample_single_chain\u001b[0;34m(ref_model, loader, criterion, num_draws, num_burnin_steps, num_steps_bw_draws, step, optimizer_kwargs, chain, seed, pbar, observor, device)\u001b[0m\n\u001b[1;32m     65\u001b[0m loss \u001b[39m=\u001b[39m criterion(y_preds, ys)\n\u001b[1;32m     66\u001b[0m \u001b[39mprint\u001b[39m(loss\u001b[39m.\u001b[39mrequires_grad, loss\u001b[39m.\u001b[39mgrad_fn)\n\u001b[0;32m---> 67\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     69\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m num_burnin_steps \u001b[39mand\u001b[39;00m (i \u001b[39m-\u001b[39m num_burnin_steps) \u001b[39m%\u001b[39m num_steps_bw_draws \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m     70\u001b[0m     draw_idx \u001b[39m=\u001b[39m (i \u001b[39m-\u001b[39m num_burnin_steps) \u001b[39m/\u001b[39m\u001b[39m/\u001b[39m num_steps_bw_draws\n",
      "File \u001b[0;32m~/Projects/devinterp/.venv/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/Projects/devinterp/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: element 0 of tensors does not require grad and does not have a grad_fn"
     ]
    }
   ],
   "source": [
    "# learner.save_checkpoint(0)\n",
    "learner.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
