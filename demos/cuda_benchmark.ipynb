{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CUDA vs CPU RLCT estimation\n",
    "\n",
    "This notebook measures how fast RLCT estimation is on CUDA vs on CPU. We check this using a standard normal crossing model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timeit\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.optim.sgd import SGD\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(1, \"/home/paperspace/devinterp\")  # TODO fix path\n",
    "\n",
    "\n",
    "from devinterp.optim.sgld import SGLD\n",
    "from devinterp.optim.sgnht import SGNHT\n",
    "from devinterp.slt.sampler import estimate_rlct, sample\n",
    "from devinterp.zoo.normal_crossing import PolyModel\n",
    "\n",
    "assert torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500000 samples 500000 batch_size on cuda, 1 cores/chains: 52.60s per estimate\n",
      "500000 samples 500000 batch_size on cpu, 1 cores/chains: 62.75s per estimate\n",
      "500000 samples 500000 batch_size on cuda, 4 cores/chains: 113.27s per estimate\n"
     ]
    }
   ],
   "source": [
    "from functools import partial\n",
    "\n",
    "sigma = 0.25\n",
    "lr = 0.0005\n",
    "criterion = F.mse_loss\n",
    "\n",
    "\n",
    "def timeit_rlct_estimation_wrapper(model, device, cores):\n",
    "    return estimate_rlct(\n",
    "        model,\n",
    "        train_loader,\n",
    "        criterion=criterion,\n",
    "        optimizer_kwargs=dict(\n",
    "            lr=lr,\n",
    "            diffusion_factor=0.01,\n",
    "            bounding_box_size=1.0,\n",
    "            num_samples=len(train_data),\n",
    "        ),\n",
    "        sampling_method=SGNHT,\n",
    "        num_chains=cores,\n",
    "        num_draws=1_000,\n",
    "        num_burnin_steps=0,\n",
    "        num_steps_bw_draws=1,\n",
    "        verbose=False,\n",
    "        device=device,\n",
    "        cores=cores\n",
    "    )\n",
    "num_train_samples=500_000\n",
    "batch_size = num_train_samples\n",
    "x = torch.normal(0, 2, size=(num_train_samples,))\n",
    "y = sigma * torch.normal(0, 1, size=(num_train_samples,))\n",
    "train_data = TensorDataset(x, y)\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "for cores in (1, 4):\n",
    "    for device in (\"cuda\", \"cpu\"):\n",
    "        powers = torch.tensor([1, 2], device=device)\n",
    "        model = PolyModel(powers)\n",
    "        w_true = torch.zeros_like(powers)\n",
    "        timeit_rlct_function = partial(timeit_rlct_estimation_wrapper, *(model, device, cores))\n",
    "        time_taken = timeit.timeit(\n",
    "            timeit_rlct_function,\n",
    "            number=5\n",
    "        )\n",
    "        print(\n",
    "            f\"{num_train_samples} samples on {device}, {cores} cores/chains: {time_taken:.2f}s per estimate\"\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
